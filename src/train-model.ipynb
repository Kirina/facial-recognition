{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c3fdd1-f8ac-4e7d-9bbe-9901b3c519a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8aaae09-3959-4087-b4e4-a36ae5521015",
   "metadata": {},
   "outputs": [],
   "source": [
    "_RAW_TRAIN_IMAGE_DIRECTORY = Path(\"../data/images/train-raw/\")\n",
    "_RAW_TRAIN_LABEL_DIRECTORY = Path(\"../data/labels/train-raw/\")\n",
    "\n",
    "_TRAIN_IMAGE_DIRECTORY = Path(\"../data/images/train/\")\n",
    "_TRAIN_LABEL_DIRECTORY = Path(\"../data/labels/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94eaf88-6bac-4912-9592-882a98d88fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of train images: 13386\n",
      "Length of images is equal to labels: True\n"
     ]
    }
   ],
   "source": [
    "def create_image_list(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        return files\n",
    "\n",
    "train_images = create_image_list(_RAW_TRAIN_IMAGE_DIRECTORY)\n",
    "train_labels = create_image_list(_RAW_TRAIN_LABEL_DIRECTORY)\n",
    "print(\"Amount of train images:\", len(train_images))\n",
    "print(\"Length of images is equal to labels:\", len(train_images) == len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401b14f4-d5d7-4449-ae57-145e5678428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotations_yolo(annotions_file_path, image_size):\n",
    "    image_width, image_height = image_size\n",
    "    annotations = []\n",
    "    with open(annotions_file_path, 'r') as file:\n",
    "        for box_annotation in file:\n",
    "            coordinates = box_annotation.strip().split()[1:]\n",
    "            x_center, y_center, width, height = map(float, coordinates)\n",
    "            x_min = int((x_center - width / 2) * image_width)\n",
    "            y_min = int((y_center - height / 2) * image_height)\n",
    "            x_max = int((x_center + width / 2) * image_width)\n",
    "            y_max = int((y_center + height / 2) * image_height)\n",
    "            annotations.append(((x_min, y_min), (x_max, y_max)))\n",
    "    return np.array(annotations, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "568fb391-5bba-4ea8-97f4-276c27112b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(5, 5))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "def show_boxes_on_image(image, annotations):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for ((x_min, y_min), (x_max, y_max)) in annotations:\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8875d551-92e6-4ffc-8db0-925aa74363f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, annotations, new_size = (300, 300)):\n",
    "    image, annotations = expand_to_square(image, annotations, new_size)\n",
    "    new_image = ImageOps.fit(image, new_size, Image.LANCZOS)\n",
    "    return new_image, annotations\n",
    "\n",
    "\n",
    "def expand_to_square(image, annotations, new_size, background_color=(255, 255, 255)):\n",
    "    \"\"\"\n",
    "    Expands rectangular image to square by adding a white border\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    if width == height:\n",
    "        return image\n",
    "    elif width > height:\n",
    "        result = Image.new(image.mode, (width, width), background_color)\n",
    "        result.paste(image, (0, (width - height) // 2))\n",
    "        new_width, new_height = result.size\n",
    "        annotations = expand_annotations(annotations, width, height, new_width, new_height, new_size)\n",
    "        return result, annotations\n",
    "    else:\n",
    "        result = Image.new(image.mode, (height, height), background_color)\n",
    "        result.paste(image, ((height - width) // 2, 0))\n",
    "        new_width, new_height = result.size\n",
    "        annotations = expand_annotations(annotations, width, height, new_width, new_height, new_size)\n",
    "        return result, annotations\n",
    "\n",
    "def expand_annotations(annotations, old_width, old_height, new_width, new_height, new_size):\n",
    "    if x_axis_change := new_width - old_width:\n",
    "        for annotation in annotations: \n",
    "            annotation[:, 0] += x_axis_change / 2\n",
    "    if y_axis_change := new_height - old_height:\n",
    "        for annotation in annotations: \n",
    "            annotation[:, 1] += y_axis_change / 2 \n",
    "    annotation[:, 0] *= new_size[0] / new_width\n",
    "    annotation[:, 1] *= new_size[1] / new_height\n",
    "    return annotations\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31578008-f36b-48e4-97ec-017b873242df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (300, 300, 1)\n",
    "image_nr = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628b1dcf-d2d2-4a31-b550-e80e89384188",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = _RAW_TRAIN_IMAGE_DIRECTORY/train_images[image_nr]\n",
    "annotations_file_path = _RAW_TRAIN_LABEL_DIRECTORY/train_labels[image_nr]\n",
    "image = Image.open(image_path)\n",
    "\n",
    "annotations = parse_annotations_yolo(annotations_file_path, image.size) \n",
    "image, annotations = resize_image(image, annotations, (input_shape[0], input_shape[1]))\n",
    "show_boxes_on_image(image, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfcba38e-03a4-43f7-b67c-54ecefd204bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# for image_index in range(len(train_images)):\n",
    "for image_index in range(100):\n",
    "    image_path = _RAW_TRAIN_IMAGE_DIRECTORY/train_images[image_nr]\n",
    "    annotations_file_path = _RAW_TRAIN_LABEL_DIRECTORY/train_labels[image_nr]\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    annotations = parse_annotations_yolo(annotations_file_path, image.size) \n",
    "    image, annotations = resize_image(image, annotations, (input_shape[0], input_shape[1]))\n",
    "\n",
    "    image_path_processed = _TRAIN_IMAGE_DIRECTORY/train_images[image_index]\n",
    "    # label_path_processed = _TRAIN_LABEL_DIRECTORY/train_labels[image_index]\n",
    "    \n",
    "    image.save(image_path_processed)\n",
    "\n",
    "    x_train.append(image_path_processed)\n",
    "    y_train.append(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76f5ad-7ce2-4375-a0c6-5e61d5134e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609f45f-6fbe-463b-819b-5ecfc8490b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037155cc-9789-46be-8991-f6cc3600a006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726c503-7fd7-48ee-ad27-1150466dcfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu'),\n",
    "    keras.layers.AveragePooling2D(2,2),\n",
    "\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    keras.layers.AveragePooling2D(2,2),\n",
    "\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    keras.Dropout(0.2),\n",
    "    keras.layers.AveragePooling2D(2,2),\n",
    "    keras.layers.Dense(units = 4),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(),\n",
    "        keras.metrics.FalseNegatives(),\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d72a30-0ad0-47d3-af66-3bf1d3b24067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
